# Performance Configuration for 10K Concurrent Users
# Risk Assessment Service - Phase 4.6 Implementation

# Service Configuration
service:
  name: "risk-assessment-service"
  version: "1.0.0"
  environment: "production"
  
# Server Configuration
server:
  port: 8080
  read_timeout: "30s"
  write_timeout: "30s"
  idle_timeout: "120s"
  max_header_bytes: 1048576 # 1MB
  
# Concurrency Configuration
concurrency:
  max_concurrent_requests: 1000
  worker_pool_size: 100
  goroutine_limit: 10000
  request_queue_size: 5000
  
# Database Configuration
database:
  max_connections: 100
  min_connections: 20
  max_idle_connections: 20
  connection_max_lifetime: "1h"
  connection_max_idle_time: "30m"
  query_timeout: "30s"
  transaction_timeout: "60s"
  
  # Connection pooling
  pool:
    max_open_conns: 100
    max_idle_conns: 20
    conn_max_lifetime: "1h"
    conn_max_idle_time: "30m"
    
  # Query optimization
  optimization:
    enable_query_cache: true
    query_cache_size: 1000
    query_cache_ttl: "5m"
    enable_prepared_statements: true
    batch_size: 1000
    
# Redis Configuration
redis:
  url: "redis://localhost:6379/0"
  pool_size: 50
  min_idle_conns: 10
  max_conn_age: "1h"
  pool_timeout: "30s"
  idle_timeout: "5m"
  idle_check_frequency: "1m"
  
  # Cache configuration
  cache:
    default_ttl: "5m"
    max_ttl: "1h"
    cleanup_interval: "10m"
    
# Performance Monitoring
monitoring:
  enabled: true
  collection_interval: "30s"
  metrics_endpoint: "/metrics"
  health_endpoint: "/health"
  
  # Metrics collection
  metrics:
    enable_system_metrics: true
    enable_application_metrics: true
    enable_custom_metrics: true
    metrics_retention: "24h"
    
  # Performance targets
  targets:
    p95_latency: "1s"
    p99_latency: "2s"
    error_rate: 0.001 # 0.1%
    throughput_rpm: 10000
    
# Load Testing Configuration
load_testing:
  enabled: true
  concurrent_users: 10000
  test_duration: "30m"
  ramp_up_time: "5m"
  target_rps: 2000
  
  # Test scenarios
  scenarios:
    - name: "risk_assessment"
      weight: 0.7
      endpoint: "/api/v1/assess/risk"
      method: "POST"
      
    - name: "batch_job_submit"
      weight: 0.2
      endpoint: "/api/v1/assess/batch"
      method: "POST"
      
    - name: "health_check"
      weight: 0.1
      endpoint: "/health"
      method: "GET"
      
# ML Model Configuration
ml_models:
  # Model loading
  model_cache_size: 10
  model_reload_interval: "1h"
  
  # Inference optimization
  inference:
    batch_size: 100
    max_concurrent_inferences: 50
    inference_timeout: "10s"
    
  # Model performance
  performance:
    enable_model_caching: true
    enable_batch_inference: true
    enable_async_inference: true
    
# External API Configuration
external_apis:
  # Rate limiting
  rate_limits:
    default: 1000 # requests per minute
    burst: 100
    
  # Timeouts
  timeouts:
    default: "30s"
    max: "60s"
    
  # Retry configuration
  retry:
    max_attempts: 3
    initial_delay: "1s"
    max_delay: "10s"
    multiplier: 2.0
    
  # Circuit breaker
  circuit_breaker:
    enabled: true
    failure_threshold: 5
    recovery_timeout: "30s"
    half_open_max_calls: 3
    
# Webhook Configuration
webhooks:
  # Delivery optimization
  delivery:
    max_concurrent_deliveries: 100
    delivery_timeout: "30s"
    retry_attempts: 3
    
  # Rate limiting
  rate_limits:
    max_deliveries_per_minute: 1000
    burst_size: 100
    
# Batch Processing Configuration
batch_processing:
  # Job processing
  max_concurrent_jobs: 10
  job_timeout: "1h"
  worker_pool_size: 50
  
  # Job queue
  queue:
    max_size: 10000
    processing_timeout: "30m"
    
# Security Configuration
security:
  # Rate limiting
  rate_limits:
    global: 10000 # requests per minute
    per_ip: 1000
    per_user: 100
    
  # Request validation
  validation:
    max_request_size: "10MB"
    max_field_size: "1MB"
    
# Logging Configuration
logging:
  level: "info"
  format: "json"
  output: "stdout"
  
  # Performance logging
  performance:
    enabled: true
    log_slow_requests: true
    slow_request_threshold: "1s"
    log_request_details: false
    
# Feature Flags
features:
  enable_performance_monitoring: true
  enable_load_testing: true
  enable_auto_scaling: true
  enable_circuit_breakers: true
  enable_retry_logic: true
  enable_caching: true
  enable_batch_processing: true
  enable_webhook_delivery: true
