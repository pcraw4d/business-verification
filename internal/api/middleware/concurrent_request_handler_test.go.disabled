package middleware

import (
	"context"
	"net/http"
	"net/http/httptest"
	"sync"
	"testing"
	"time"
)

func TestNewRequestQueue(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     10,
		QueueSize:      100,
		RequestTimeout: 5 * time.Second,
		RateLimit:      50.0,
		BurstLimit:     100,
		EnableMetrics:  true,
		PriorityLevels: 5,
	}

	queue := NewRequestQueue(config)
	defer queue.Shutdown()

	if queue.workers != config.MaxWorkers {
		t.Errorf("Expected %d workers, got %d", config.MaxWorkers, queue.workers)
	}

	if cap(queue.queue) != config.QueueSize {
		t.Errorf("Expected queue size %d, got %d", config.QueueSize, cap(queue.queue))
	}
}

func TestDefaultQueueConfig(t *testing.T) {
	config := DefaultQueueConfig()

	if config.MaxWorkers != 50 {
		t.Errorf("Expected 50 workers, got %d", config.MaxWorkers)
	}

	if config.QueueSize != 1000 {
		t.Errorf("Expected queue size 1000, got %d", config.QueueSize)
	}

	if config.RateLimit != 100.0 {
		t.Errorf("Expected rate limit 100.0, got %f", config.RateLimit)
	}
}

func TestRequestQueue_EnqueueRequest(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     5,
		QueueSize:      10,
		RequestTimeout: 1 * time.Second,
		RateLimit:      100.0,
		BurstLimit:     200,
	}

	queue := NewRequestQueue(config)
	defer queue.Shutdown()

	// Create a test request
	req := httptest.NewRequest("POST", "/test", nil)
	w := httptest.NewRecorder()

	handler := func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
		w.Write([]byte("test response"))
	}

	// Test successful enqueue
	err := queue.EnqueueRequest(req, w, handler, 1)
	if err != nil {
		t.Errorf("Expected no error, got %v", err)
	}

	// Wait a bit for processing
	time.Sleep(100 * time.Millisecond)

	metrics := queue.GetMetrics()
	if metrics.TotalRequests != 1 {
		t.Errorf("Expected 1 total request, got %d", metrics.TotalRequests)
	}
}

func TestRequestQueue_ConcurrentRequests(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     10,
		QueueSize:      50,
		RequestTimeout: 2 * time.Second,
		RateLimit:      1000.0, // High rate limit for testing
		BurstLimit:     2000,
	}

	queue := NewRequestQueue(config)
	defer queue.Shutdown()

	var wg sync.WaitGroup
	requestCount := 20

	// Send concurrent requests
	for i := 0; i < requestCount; i++ {
		wg.Add(1)
		go func(id int) {
			defer wg.Done()

			req := httptest.NewRequest("POST", "/test", nil)
			w := httptest.NewRecorder()

			handler := func(w http.ResponseWriter, r *http.Request) {
				time.Sleep(50 * time.Millisecond) // Simulate processing time
				w.WriteHeader(http.StatusOK)
				w.Write([]byte("response"))
			}

			err := queue.EnqueueRequest(req, w, handler, 1)
			if err != nil {
				t.Errorf("Request %d failed to enqueue: %v", id, err)
			}
		}(i)
	}

	wg.Wait()

	// Wait for processing to complete
	time.Sleep(500 * time.Millisecond)

	metrics := queue.GetMetrics()
	if metrics.TotalRequests != int64(requestCount) {
		t.Errorf("Expected %d total requests, got %d", requestCount, metrics.TotalRequests)
	}
}

func TestRequestQueue_RateLimiting(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     5,
		QueueSize:      10,
		RequestTimeout: 1 * time.Second,
		RateLimit:      10.0, // Low rate limit for testing
		BurstLimit:     5,
	}

	queue := NewRequestQueue(config)
	defer queue.Shutdown()

	// Send requests rapidly
	for i := 0; i < 20; i++ {
		req := httptest.NewRequest("POST", "/test", nil)
		w := httptest.NewRecorder()

		handler := func(w http.ResponseWriter, r *http.Request) {
			w.WriteHeader(http.StatusOK)
		}

		err := queue.EnqueueRequest(req, w, handler, 1)
		if err != nil && i < 15 { // First 15 should succeed due to burst limit
			t.Errorf("Request %d failed unexpectedly: %v", i, err)
		}
	}

	time.Sleep(100 * time.Millisecond)

	metrics := queue.GetMetrics()
	if metrics.FailedRequests == 0 {
		t.Log("No requests were rate limited - this may be normal depending on timing")
	}
}

func TestRequestQueue_TimeoutHandling(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     2,
		QueueSize:      5,
		RequestTimeout: 100 * time.Millisecond, // Short timeout
		RateLimit:      100.0,
		BurstLimit:     200,
	}

	queue := NewRequestQueue(config)
	defer queue.Shutdown()

	req := httptest.NewRequest("POST", "/test", nil)
	w := httptest.NewRecorder()

	// Handler that takes longer than timeout
	handler := func(w http.ResponseWriter, r *http.Request) {
		time.Sleep(200 * time.Millisecond) // Longer than timeout
		w.WriteHeader(http.StatusOK)
	}

	err := queue.EnqueueRequest(req, w, handler, 1)
	if err != nil {
		t.Errorf("Failed to enqueue request: %v", err)
	}

	// Wait for processing
	time.Sleep(300 * time.Millisecond)

	metrics := queue.GetMetrics()
	if metrics.ProcessedRequests != 1 {
		t.Errorf("Expected 1 processed request, got %d", metrics.ProcessedRequests)
	}
}

func TestDeterminePriority(t *testing.T) {
	tests := []struct {
		path     string
		expected int
	}{
		{"/health", 1},
		{"/status", 1},
		{"/v1/classify", 3},
		{"/v1/classify/batch", 4},
		{"/other", 5},
	}

	for _, test := range tests {
		req := httptest.NewRequest("POST", test.path, nil)
		priority := determinePriority(req)
		if priority != test.expected {
			t.Errorf("For path %s, expected priority %d, got %d", test.path, test.expected, priority)
		}
	}
}

func TestConcurrentRequestMiddleware(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     5,
		QueueSize:      10,
		RequestTimeout: 1 * time.Second,
		RateLimit:      100.0,
		BurstLimit:     200,
	}

	middleware := ConcurrentRequestMiddleware(config)

	handler := func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
		w.Write([]byte("success"))
	}

	wrappedHandler := middleware(handler)

	// Test successful request
	req := httptest.NewRequest("POST", "/v1/classify", nil)
	w := httptest.NewRecorder()

	wrappedHandler(w, req)

	if w.Code != http.StatusOK {
		t.Errorf("Expected status 200, got %d", w.Code)
	}
}

func TestQueueHealthMiddleware(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     5,
		QueueSize:      10,
		RequestTimeout: 1 * time.Second,
		RateLimit:      100.0,
		BurstLimit:     200,
	}

	queue := NewRequestQueue(config)
	defer queue.Shutdown()

	middleware := QueueHealthMiddleware(queue)

	handler := func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
	}

	wrappedHandler := middleware(handler)

	// Test health endpoint
	req := httptest.NewRequest("GET", "/queue/health", nil)
	w := httptest.NewRecorder()

	wrappedHandler(w, req)

	if w.Code != http.StatusOK {
		t.Errorf("Expected status 200, got %d", w.Code)
	}

	if w.Header().Get("Content-Type") != "application/json" {
		t.Errorf("Expected Content-Type application/json, got %s", w.Header().Get("Content-Type"))
	}
}

func TestRequestQueue_Shutdown(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     5,
		QueueSize:      10,
		RequestTimeout: 1 * time.Second,
		RateLimit:      100.0,
		BurstLimit:     200,
	}

	queue := NewRequestQueue(config)

	// Send a request
	req := httptest.NewRequest("POST", "/test", nil)
	w := httptest.NewRecorder()

	handler := func(w http.ResponseWriter, r *http.Request) {
		time.Sleep(100 * time.Millisecond)
		w.WriteHeader(http.StatusOK)
	}

	err := queue.EnqueueRequest(req, w, handler, 1)
	if err != nil {
		t.Errorf("Failed to enqueue request: %v", err)
	}

	// Shutdown the queue
	queue.Shutdown()

	// Try to enqueue another request (should fail)
	err = queue.EnqueueRequest(req, w, handler, 1)
	if err == nil {
		t.Error("Expected error when enqueueing to shutdown queue")
	}
}

func TestRequestQueue_Metrics(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     2,
		QueueSize:      5,
		RequestTimeout: 1 * time.Second,
		RateLimit:      100.0,
		BurstLimit:     200,
	}

	queue := NewRequestQueue(config)
	defer queue.Shutdown()

	// Send a request
	req := httptest.NewRequest("POST", "/test", nil)
	w := httptest.NewRecorder()

	handler := func(w http.ResponseWriter, r *http.Request) {
		w.WriteHeader(http.StatusOK)
	}

	err := queue.EnqueueRequest(req, w, handler, 1)
	if err != nil {
		t.Errorf("Failed to enqueue request: %v", err)
	}

	// Wait for processing
	time.Sleep(100 * time.Millisecond)

	metrics := queue.GetMetrics()
	if metrics.TotalRequests != 1 {
		t.Errorf("Expected 1 total request, got %d", metrics.TotalRequests)
	}

	if metrics.ProcessedRequests != 1 {
		t.Errorf("Expected 1 processed request, got %d", metrics.ProcessedRequests)
	}

	if metrics.QueueSize < 0 {
		t.Errorf("Queue size should be non-negative, got %d", metrics.QueueSize)
	}
}

func TestRequestQueue_ContextCancellation(t *testing.T) {
	config := &QueueConfig{
		MaxWorkers:     2,
		QueueSize:      5,
		RequestTimeout: 1 * time.Second,
		RateLimit:      100.0,
		BurstLimit:     200,
	}

	queue := NewRequestQueue(config)
	defer queue.Shutdown()

	// Create a request with a cancellable context
	ctx, cancel := context.WithCancel(context.Background())
	req := httptest.NewRequest("POST", "/test", nil).WithContext(ctx)
	w := httptest.NewRecorder()

	handler := func(w http.ResponseWriter, r *http.Request) {
		time.Sleep(200 * time.Millisecond)
		w.WriteHeader(http.StatusOK)
	}

	err := queue.EnqueueRequest(req, w, handler, 1)
	if err != nil {
		t.Errorf("Failed to enqueue request: %v", err)
	}

	// Cancel the context
	cancel()

	// Wait for processing
	time.Sleep(300 * time.Millisecond)

	metrics := queue.GetMetrics()
	if metrics.ProcessedRequests != 1 {
		t.Errorf("Expected 1 processed request, got %d", metrics.ProcessedRequests)
	}
}
