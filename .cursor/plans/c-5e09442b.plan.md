---
name: Classification System Rebuild - Complete Implementation Plan
overview: ""
todos: []
---

# Classification System Rebuild - Complete Implementation Plan

## Executive Summary

This plan rebuilds the classification system to achieve:

- **Industry Accuracy**: >95% (from current 0%)
- **Code Accuracy**: >90% (from current 4.2%)
- **Response Time**: <10s (P99), <5s (P95), <2s (P50)
- **ML Trigger**: Only if base confidence >0.8
- **Output Format**: Primary industry, MCC, NAICS, SIC, explanation, confidence

The plan leverages existing database enhancements (trigram indexes, full-text search), implements comprehensive performance optimizations (parallelization, caching, query batching), and removes all legacy classification code.

---

## Phase 1: Fix Multi-Strategy Classifier (Week 1-2)

### 1.1 Fix Keyword Strategy

**File**: `internal/classification/multi_strategy_classifier.go`

**Current Issue**: Keyword strategy doesn't leverage trigram indexes and full-text search.

**Implementation**:

```go
// classifyByKeywords - Enhanced with database optimizations
func (msc *MultiStrategyClassifier) classifyByKeywords(
    ctx context.Context,
    keywords []string,
    businessName string,
) *ClassificationStrategy {
    // Use trigram similarity for fuzzy matching
    query := `
        SELECT 
            i.id,
            i.name,
            SUM(kw.base_weight * similarity(kw.keyword, $1)) as score,
            COUNT(DISTINCT kw.keyword) as match_count
        FROM industries i
        JOIN keyword_weights kw ON kw.industry_id = i.id
        WHERE similarity(kw.keyword, $1) > 0.3
           OR kw.keyword = ANY($2)
        GROUP BY i.id, i.name
        ORDER BY score DESC, match_count DESC
        LIMIT 10
    `
    
    // Execute with context timeout
    ctx, cancel := context.WithTimeout(ctx, 2*time.Second)
    defer cancel()
    
    // Use prepared statement for performance
    rows, err := msc.keywordRepo.Query(ctx, query, businessName, keywords)
    // ... process results
}
```

**Changes**:

- Leverage trigram indexes (`similarity()` function)
- Use full-text search for semantic matching
- Add context timeout (2s)
- Use prepared statements
- Batch keyword lookups

**Expected Impact**: 85%+ accuracy for keyword strategy

### 1.2 Fix Entity Recognition

**File**: `internal/classification/nlp/entity_recognizer.go`

**Current Issue**: Limited entity patterns, doesn't extract business-specific entities well.

**Implementation**:

```go
// ExtractEntities - Enhanced with business-specific patterns
func (er *EntityRecognizer) ExtractEntities(text string) []Entity {
    entities := []Entity{}
    
    // Business type patterns (expanded)
    businessTypePatterns := []struct {
        pattern *regexp.Regexp
        entityType string
    }{
        {regexp.MustCompile(`(?i)\b(restaurant|cafe|bistro|diner)\b`), "business_type"},
        {regexp.MustCompile(`(?i)\b(retail|store|shop|boutique)\b`), "business_type"},
        {regexp.MustCompile(`(?i)\b(software|tech|IT|development)\b`), "business_type"},
        // ... 50+ more patterns
    }
    
    // Extract entities with confidence scores
    for _, pattern := range businessTypePatterns {
        matches := pattern.pattern.FindAllString(text, -1)
        for _, match := range matches {
            entities = append(entities, Entity{
                Text: match,
                Type: pattern.entityType,
                Confidence: 0.8, // High confidence for pattern matches
            })
        }
    }
    
    return entities
}
```

**Changes**:

- Expand entity patterns from ~20 to 100+
- Add business-specific entity types
- Include confidence scores
- Use regex compilation caching

**Expected Impact**: 80%+ accuracy for entity strategy

### 1.3 Fix Topic Modeling

**File**: `internal/classification/nlp/topic_modeler.go`

**Current Issue**: TF-IDF not calibrated, doesn't map topics to industries well.

**Implementation**:

```go
// IdentifyTopicsWithDetails - Enhanced with industry mapping
func (tm *TopicModeler) IdentifyTopicsWithDetails(keywords []string) []TopicScore {
    // Calculate TF-IDF scores
    tfidfScores := tm.calculateTFIDF(keywords)
    
    // Map topics to industries using database
    industryTopics := tm.mapTopicsToIndustries(ctx, tfidfScores)
    
    // Calibrate scores based on historical accuracy
    calibratedScores := tm.calibrateScores(industryTopics)
    
    return calibratedScores
}

// mapTopicsToIndustries - New method
func (tm *TopicModeler) mapTopicsToIndustries(
    ctx context.Context,
    topics []TopicScore,
) []TopicScore {
    // Query database for industry-topic relationships
    query := `
        SELECT industry_id, topic, relevance_score
        FROM industry_topics
        WHERE topic = ANY($1)
        ORDER BY relevance_score DESC
    `
    
    // Map topics to industries with relevance scores
    // ... implementation
}
```

**Changes**:

- Add industry-topic mapping table
- Calibrate TF-IDF scores
- Use historical accuracy data
- Cache topic-industry mappings

**Expected Impact**: 75%+ accuracy for topic strategy

### 1.4 Fix Co-Occurrence Strategy

**File**: `internal/classification/multi_strategy_classifier.go`

**Current Issue**: Co-occurrence doesn't analyze relationships between keywords/entities.

**Implementation**:

```go
// classifyByCoOccurrence - Enhanced with relationship analysis
func (msc *MultiStrategyClassifier) classifyByCoOccurrence(
    ctx context.Context,
    keywords []string,
    entities []nlp.Entity,
) *ClassificationStrategy {
    // Analyze keyword co-occurrence patterns
    coOccurrencePatterns := msc.analyzeCoOccurrencePatterns(keywords, entities)
    
    // Query database for industry patterns
    query := `
        SELECT 
            i.id,
            i.name,
            COUNT(DISTINCT kp.keyword_pair) as pattern_matches,
            AVG(kp.co_occurrence_score) as avg_score
        FROM industries i
        JOIN keyword_patterns kp ON kp.industry_id = i.id
        WHERE kp.keyword_pair = ANY($1)
        GROUP BY i.id, i.name
        HAVING COUNT(DISTINCT kp.keyword_pair) >= 2
        ORDER BY pattern_matches DESC, avg_score DESC
        LIMIT 5
    `
    
    // Execute query and process results
    // ... implementation
}

// analyzeCoOccurrencePatterns - New method
func (msc *MultiStrategyClassifier) analyzeCoOccurrencePatterns(
    keywords []string,
    entities []nlp.Entity,
) []string {
    patterns := []string{}
    
    // Generate keyword pairs
    for i := 0; i < len(keywords)-1; i++ {
        for j := i + 1; j < len(keywords); j++ {
            pair := fmt.Sprintf("%s|%s", keywords[i], keywords[j])
            patterns = append(patterns, pair)
        }
    }
    
    // Generate entity-keyword pairs
    for _, entity := range entities {
        for _, keyword := range keywords {
            pair := fmt.Sprintf("%s|%s", entity.Text, keyword)
            patterns = append(patterns, pair)
        }
    }
    
    return patterns
}
```

**Changes**:

- Add keyword pattern analysis
- Query database for co-occurrence patterns
- Analyze entity-keyword relationships
- Cache pattern-industry mappings

**Expected Impact**: 70%+ accuracy for co-occurrence strategy

### 1.5 Fix Combination Logic

**File**: `internal/classification/multi_strategy_classifier.go`

**Current Issue**: Complex combination logic with multiple fallbacks, not using simple weighted average.

**Implementation**:

```go
// combineStrategies - Simplified to weighted average
func (msc *MultiStrategyClassifier) combineStrategies(
    strategies []ClassificationStrategy,
) (map[int]float64, string, float64, string) {
    // Strategy weights (fixed, based on accuracy)
    weights := map[string]float64{
        "keyword":      0.40,
        "entity":       0.25,
        "topic":        0.20,
        "co_occurrence": 0.15,
    }
    
    // Combine scores using weighted average
    combinedScores := make(map[int]float64)
    totalWeight := 0.0
    
    for _, strategy := range strategies {
        weight := weights[strategy.StrategyName]
        if weight == 0 {
            continue
        }
        
        score := strategy.Score * strategy.Confidence
        combinedScores[strategy.IndustryID] += score * weight
        totalWeight += weight
    }
    
    // Normalize scores
    for industryID := range combinedScores {
        combinedScores[industryID] /= totalWeight
    }
    
    // Find primary industry (highest score)
    var primaryIndustryID int
    var maxScore float64
    for industryID, score := range combinedScores {
        if score > maxScore {
            maxScore = score
            primaryIndustryID = industryID
        }
    }
    
    // Get industry name
    industryName := msc.getIndustryName(ctx, primaryIndustryID)
    
    // Calculate final confidence
    confidence := maxScore
    if confidence < 0.35 {
        confidence = 0.35 // Minimum confidence
    }
    if confidence > 1.0 {
        confidence = 1.0
    }
    
    // Generate reasoning
    reasoning := msc.generateReasoning(strategies, primaryIndustryID, confidence)
    
    return combinedScores, industryName, confidence, reasoning
}
```

**Changes**:

- Simplify to weighted average (no complex fallbacks)
- Use fixed weights based on strategy accuracy
- Normalize scores properly
- Generate clear reasoning

**Expected Impact**: 90%+ accuracy when all strategies agree

---

## Phase 2: Performance Optimizations (Week 2-3)

### 2.1 Multi-Strategy Parallelization

**File**: `internal/classification/multi_strategy_classifier.go`

**Implementation**:

```go
// ClassifyWithMultiStrategy - Enhanced with parallel execution
func (msc *MultiStrategyClassifier) ClassifyWithMultiStrategy(
    ctx context.Context,
    businessName, description, websiteURL string,
) (*MultiStrategyResult, error) {
    startTime := time.Now()
    
    // Extract keywords (parallel with entity extraction)
    keywordsChan := make(chan []string, 1)
    entitiesChan := make(chan []nlp.Entity, 1)
    var wg sync.WaitGroup
    
    // Extract keywords
    wg.Add(1)
    go func() {
        defer wg.Done()
        keywords, _ := msc.extractKeywords(ctx, businessName, websiteURL)
        keywordsChan <- keywords
    }()
    
    // Extract entities (can be done in parallel)
    wg.Add(1)
    go func() {
        defer wg.Done()
        combinedText := msc.combineTextForAnalysis(businessName, description, []string{})
        entities := msc.entityRecognizer.ExtractEntities(combinedText)
        entitiesChan <- entities
    }()
    
    wg.Wait()
    close(keywordsChan)
    close(entitiesChan)
    
    keywords := <-keywordsChan
    entities := <-entitiesChan
    
    // Run all strategies in parallel
    strategyChan := make(chan ClassificationStrategy, 4)
    var strategyWg sync.WaitGroup
    
    // Strategy 1: Keyword (40% weight)
    strategyWg.Add(1)
    go func() {
        defer strategyWg.Done()
        strategyCtx, cancel := context.WithTimeout(ctx, 3*time.Second)
        defer cancel()
        strategy := msc.classifyByKeywords(strategyCtx, keywords, businessName)
        if strategy != nil {
            strategyChan <- *strategy
        }
    }()
    
    // Strategy 2: Entity (25% weight)
    strategyWg.Add(1)
    go func() {
        defer strategyWg.Done()
        strategyCtx, cancel := context.WithTimeout(ctx, 3*time.Second)
        defer cancel()
        strategy := msc.classifyByEntities(strategyCtx, entities, keywords)
        if strategy != nil {
            strategyChan <- *strategy
        }
    }()
    
    // Strategy 3: Topic (20% weight)
    strategyWg.Add(1)
    go func() {
        defer strategyWg.Done()
        strategyCtx, cancel := context.WithTimeout(ctx, 3*time.Second)
        defer cancel()
        topicScores := msc.topicModeler.IdentifyTopicsWithDetails(keywords)
        strategy := msc.classifyByTopics(strategyCtx, topicScores)
        if strategy != nil {
            strategyChan <- *strategy
        }
    }()
    
    // Strategy 4: Co-occurrence (15% weight)
    strategyWg.Add(1)
    go func() {
        defer strategyWg.Done()
        strategyCtx, cancel := context.WithTimeout(ctx, 3*time.Second)
        defer cancel()
        strategy := msc.classifyByCoOccurrence(strategyCtx, keywords, entities)
        if strategy != nil {
            strategyChan <- *strategy
        }
    }()
    
    strategyWg.Wait()
    close(strategyChan)
    
    // Collect strategies
    strategies := []ClassificationStrategy{}
    for strategy := range strategyChan {
        strategies = append(strategies, strategy)
    }
    
    // Combine strategies
    combinedScores, primaryIndustry, confidence, reasoning := msc.combineStrategies(strategies)
    
    // Apply confidence calibration
    calibratedConfidence := msc.calibrator.AdjustConfidence(confidence)
    
    return &MultiStrategyResult{
        PrimaryIndustry: primaryIndustry,
        Confidence:      calibratedConfidence,
        Strategies:      strategies,
        CombinedScores:  combinedScores,
        Reasoning:       reasoning,
        ProcessingTime:  time.Since(startTime),
        Keywords:        keywords,
        Entities:        entities,
    }, nil
}
```

**Expected Impact**: 60-70% faster (parallel vs sequential)

### 2.2 Query Batching

**File**: `internal/classification/repository/supabase_repository.go`

**Implementation**:

```go
// BatchFindKeywords - New method for batch keyword lookups
func (r *SupabaseKeywordRepository) BatchFindKeywords(
    ctx context.Context,
    keywords []string,
) (map[string][]IndustryMatch, error) {
    if len(keywords) == 0 {
        return make(map[string][]IndustryMatch), nil
    }
    
    // Single query instead of N queries
    query := `
        SELECT 
            kw.keyword,
            kw.industry_id,
            i.name as industry_name,
            kw.base_weight,
            similarity(kw.keyword, k.keyword) as similarity_score
        FROM keyword_weights kw
        JOIN industries i ON i.id = kw.industry_id
        CROSS JOIN (SELECT unnest($1::text[]) as keyword) k
        WHERE kw.keyword = ANY($1)
           OR similarity(kw.keyword, k.keyword) > 0.3
        ORDER BY kw.keyword, similarity_score DESC
    `
    
    // Execute with timeout
    ctx, cancel := context.WithTimeout(ctx, 2*time.Second)
    defer cancel()
    
    rows, err := r.db.QueryContext(ctx, query, pq.Array(keywords))
    if err != nil {
        return nil, fmt.Errorf("batch keyword lookup failed: %w", err)
    }
    defer rows.Close()
    
    // Process results into map
    results := make(map[string][]IndustryMatch)
    for rows.Next() {
        var keyword string
        var match IndustryMatch
        if err := rows.Scan(&keyword, &match.IndustryID, &match.IndustryName, &match.Weight, &match.Similarity); err != nil {
            continue
        }
        results[keyword] = append(results[keyword], match)
    }
    
    return results, nil
}
```

**Expected Impact**: 80-90% reduction in database round trips

### 2.3 Enhanced Caching

**File**: `internal/classification/cache/request_cache.go` (enhance existing)

**Implementation**:

```go
// PredictiveCache - New method for predictive caching
type PredictiveCache struct {
    cache      *RequestCache
    patterns   map[string][]string // business_name_pattern -> likely_keywords
    logger     *log.Logger
}

// PreloadCache - Pre-cache likely requests
func (pc *PredictiveCache) PreloadCache(ctx context.Context, businessName string) {
    // Generate name variations
    variations := pc.generateNameVariations(businessName)
    
    // Pre-cache in background
    go func() {
        for _, variation := range variations {
            // Pre-classify and cache
            result, err := pc.classifyAndCache(ctx, variation)
            if err == nil {
                pc.logger.Printf("✅ Pre-cached: %s", variation)
            }
        }
    }()
}

// generateNameVariations - Generate likely name variations
func (pc *PredictiveCache) generateNameVariations(name string) []string {
    variations := []string{name}
    
    // Remove common suffixes
    suffixes := []string{" Inc", " LLC", " Corp", " Ltd", " Co"}
    for _, suffix := range suffixes {
        if strings.HasSuffix(name, suffix) {
            variations = append(variations, strings.TrimSuffix(name, suffix))
        }
    }
    
    // Add common prefixes
    prefixes := []string{"The ", "A "}
    for _, prefix := range prefixes {
        if !strings.HasPrefix(name, prefix) {
            variations = append(variations, prefix+name)
        }
    }
    
    return variations
}
```

**Expected Impact**: 70-80% cache hit rate

### 2.4 Parallel Code Generation

**File**: `internal/classification/classifier.go`

**Implementation**:

```go
// GenerateCodesParallel - Generate MCC, NAICS, SIC codes in parallel
func (g *ClassificationCodeGenerator) GenerateCodesParallel(
    ctx context.Context,
    industryID int,
) (*ClassificationCodesInfo, error) {
    codesChan := make(chan CodesResult, 3)
    var wg sync.WaitGroup
    
    // Query MCC codes
    wg.Add(1)
    go func() {
        defer wg.Done()
        ctx, cancel := context.WithTimeout(ctx, 2*time.Second)
        defer cancel()
        mccCodes, _ := g.repo.GetClassificationCodesByType(ctx, "MCC")
        codesChan <- CodesResult{Type: "MCC", Codes: mccCodes}
    }()
    
    // Query NAICS codes
    wg.Add(1)
    go func() {
        defer wg.Done()
        ctx, cancel := context.WithTimeout(ctx, 2*time.Second)
        defer cancel()
        naicsCodes, _ := g.repo.GetClassificationCodesByType(ctx, "NAICS")
        codesChan <- CodesResult{Type: "NAICS", Codes: naicsCodes}
    }()
    
    // Query SIC codes
    wg.Add(1)
    go func() {
        defer wg.Done()
        ctx, cancel := context.WithTimeout(ctx, 2*time.Second)
        defer cancel()
        sicCodes, _ := g.repo.GetClassificationCodesByType(ctx, "SIC")
        codesChan <- CodesResult{Type: "SIC", Codes: sicCodes}
    }()
    
    wg.Wait()
    close(codesChan)
    
    // Collect results
    codesInfo := &ClassificationCodesInfo{}
    for result := range codesChan {
        switch result.Type {
        case "MCC":
            codesInfo.MCCCodes = result.Codes
        case "NAICS":
            codesInfo.NAICSCodes = result.Codes
        case "SIC":
            codesInfo.SICCodes = result.Codes
        }
    }
    
    return codesInfo, nil
}
```

**Expected Impact**: 50-60% faster code generation

---

## Phase 3: ML Enhancement (Week 3-4)

### 3.1 ML Trigger Logic

**File**: `internal/classification/service.go`

**Implementation**:

```go
// DetectIndustry - Enhanced with ML trigger logic
func (s *IndustryDetectionService) DetectIndustry(
    ctx context.Context,
    businessName, description, websiteURL string,
) (*IndustryDetectionResult, error) {
    // Step 1: Run multi-strategy classifier (base classification)
    result, err := s.multiStrategyClassifier.ClassifyWithMultiStrategy(
        ctx, businessName, description, websiteURL,
    )
    if err != nil {
        return nil, fmt.Errorf("multi-strategy classification failed: %w", err)
    }
    
    // Step 2: Check if ML validation is needed (confidence >0.8)
    if result.Confidence >= 0.8 && s.useML && s.multiMethodClassifier != nil {
        // ML validation (not replacement)
        mlResult, err := s.multiMethodClassifier.ClassifyWithMultipleMethods(
            ctx, businessName, description, websiteURL,
        )
        if err == nil && mlResult != nil {
            // Check for consensus
            if mlResult.PrimaryIndustry == result.PrimaryIndustry {
                // Consensus - boost confidence
                result.Confidence = math.Min(result.Confidence + 0.1, 1.0)
                result.Reasoning += " (ML validated with consensus)"
            } else {
                // Disagreement - use base result but note ML suggestion
                result.Reasoning += fmt.Sprintf(" (ML suggested: %s, but base classification used)", mlResult.PrimaryIndustry)
            }
        }
    }
    
    // Step 3: Return result
    return &IndustryDetectionResult{
        IndustryName:   result.PrimaryIndustry,
        Confidence:     result.Confidence,
        Method:         "multi_strategy",
        Keywords:       result.Keywords,
        Reasoning:      result.Reasoning,
        ProcessingTime: result.ProcessingTime,
    }, nil
}
```

**Changes**:

- ML only triggers if confidence >= 0.8
- ML validates (doesn't replace) base classification
- Consensus boosts confidence
- Disagreement uses base result

**Expected Impact**: ML used only when beneficial, maintains >95% accuracy

---

## Phase 4: Database Optimization (Week 4-5)

### 4.1 Leverage Trigram Indexes

**File**: `internal/classification/repository/supabase_repository.go`

**Implementation**:

```go
// ClassifyBusinessByKeywords - Enhanced with trigram indexes
func (r *SupabaseKeywordRepository) ClassifyBusinessByKeywords(
    ctx context.Context,
    keywords []string,
) (*ClassificationResult, error) {
    // Use trigram similarity for fuzzy matching
    query := `
        SELECT 
            i.id,
            i.name,
            SUM(kw.base_weight * similarity(kw.keyword, k.keyword)) as score,
            COUNT(DISTINCT kw.keyword) as match_count,
            array_agg(DISTINCT kw.keyword) as matched_keywords
        FROM industries i
        JOIN keyword_weights kw ON kw.industry_id = i.id
        CROSS JOIN (SELECT unnest($1::text[]) as keyword) k
        WHERE similarity(kw.keyword, k.keyword) > 0.3
           OR kw.keyword = ANY($1)
        GROUP BY i.id, i.name
        HAVING COUNT(DISTINCT kw.keyword) >= 1
        ORDER BY score DESC, match_count DESC
        LIMIT 10
    `
    
    // Execute with prepared statement
    rows, err := r.db.QueryContext(ctx, query, pq.Array(keywords))
    // ... process results
}
```

**Expected Impact**: 50-60% faster keyword matching

### 4.2 Leverage Full-Text Search

**File**: `internal/classification/repository/supabase_repository.go`

**Implementation**:

```go
// FindCodesByFullTextSearch - New method using full-text search
func (r *SupabaseKeywordRepository) FindCodesByFullTextSearch(
    ctx context.Context,
    searchText string,
    codeType string,
) ([]*ClassificationCode, error) {
    query := `
        SELECT 
            code,
            code_type,
            description,
            industry_id,
            ts_rank(
                to_tsvector('english', description),
                to_tsquery('english', $1)
            ) as relevance
        FROM classification_codes
        WHERE code_type = $2
          AND to_tsvector('english', description) @@ to_tsquery('english', $1)
        ORDER BY relevance DESC
        LIMIT 3
    `
    
    rows, err := r.db.QueryContext(ctx, query, searchText, codeType)
    // ... process results
}
```

**Expected Impact**: Better semantic matching for codes

---

## Phase 5: Legacy Code Removal (Week 5)

### 5.1 Remove MultiMethodClassifier

**Files to Remove**:

- `internal/classification/multi_method_classifier.go` (1997 lines)
- `internal/classification/multi_method_classifier_test.go` (if exists)

**Files to Update**:

- `internal/classification/service.go`: Remove `multiMethodClassifier` field and related methods
- `internal/classification/methods/ml_method.go`: Update to work with MultiStrategyClassifier only

**Migration**:

- Move ML validation logic to `service.go` (as shown in Phase 3.1)
- Keep `methods/ml_method.go` but simplify to work with MultiStrategyClassifier

### 5.2 Remove Legacy Website Cache

**File**: `internal/classification/multi_method_classifier.go` (lines 21-70)

**Remove**:

- `CachedWebsiteContentLegacy` type
- `WebsiteCache` struct and methods

**Replace With**:

- Use existing `internal/classification/cache/request_cache.go`

### 5.3 Remove Backup Files

**Files to Remove**:

- All `.bak` files in `internal/classification/`:
  - `accuracy_calculation_demo.go.bak`
  - `business_context_filtering_test.go.bak`
  - `classifier_test.go.bak`
  - `comprehensive_performance_monitor_test.go.bak`
  - `comprehensive_performance_monitoring_test.go.bak`
  - `container_test.go.bak`
  - `e2e_test.go.bak`
  - `enhanced_database_monitor_test.go.bak`
  - `enhanced_scoring_algorithm_test.go.bak`
  - `method_registry_test.go.bak`
  - `multi_strategy_classifier_test.go.bak`
  - `parallel_processing_test.go.bak`
  - `performance_based_weight_adjuster_integration_test.go.bak`
  - `performance_based_weight_adjuster_test.go.bak`
  - `performance_dashboard_service.go.bak`
  - `performance_dashboards_test.go.bak`
  - `performance_monitoring_benchmarks_test.go.bak`
  - `performance_test.go.bak`
  - `performance_testing_test.go.bak`
  - `reporting_system_test.go.bak`
  - `service_test.go.bak`
  - `smart_website_crawler_keyword_test.go.bak`
  - `task_2_1_comprehensive_test.go.bak`
  - `unified_classifier.go.bak`

### 5.4 Remove Unused Pattern Matching Functions

**File**: `internal/classification/repository/supabase_repository.go`

**Remove** (lines 1763-1789):

- `GetPatternsByIndustry` (returns empty, not implemented)
- `AddPattern` (returns error, not implemented)
- `UpdatePattern` (returns error, not implemented)
- `DeletePattern` (returns error, not implemented)

**Reason**: Pattern matching not implemented, using keyword-based classification instead.

### 5.5 Remove Unused Classification Methods

**File**: `internal/classification/service.go`

**Remove** (if exists):

- `classifyByHybridAnalysis` (deprecated)
- `classifyByWebsiteAnalysis` (deprecated)
- `classifyBySearchAnalysis` (deprecated)

**Keep**:

- `DetectIndustry` (main entry point)
- `classifyByKeywords` (used by MultiStrategyClassifier)

### 5.6 Clean Up Unused Imports and Types

**Files to Update**:

- Remove unused imports from all classification files
- Remove unused type definitions
- Remove commented-out code

---

## Phase 6: Best-in-Class Features (Week 6)

### 6.1 Continuous Learning System

**New File**: `internal/classification/learning/feedback_learner.go`

**Implementation**:

```go
// FeedbackLearner learns from user feedback
type FeedbackLearner struct {
    keywordRepo repository.KeywordRepository
    logger      *log.Logger
}

// LearnFromFeedback updates keyword weights based on feedback
func (fl *FeedbackLearner) LearnFromFeedback(
    ctx context.Context,
    feedback *ClassificationFeedback,
) error {
    if feedback.IsCorrect {
        // Boost keyword weights
        return fl.boostKeywordWeights(ctx, feedback.Keywords, feedback.IndustryID)
    } else {
        // Adjust keyword weights, add negative keywords
        return fl.adjustKeywordWeights(ctx, feedback.Keywords, feedback.CorrectIndustryID)
    }
}
```

### 6.2 A/B Testing Framework

**New File**: `internal/classification/ab_test_manager.go` (enhance existing)

**Implementation**:

```go
// ABTestFramework tests different classification strategies
type ABTestFramework struct {
    experiments map[string]*Experiment
    logger      *log.Logger
}

// TestClassification runs A/B test
func (ab *ABTestFramework) TestClassification(
    ctx context.Context,
    req *ClassificationRequest,
) (*ClassificationResult, error) {
    variant := ab.getVariant(req.UserID)
    
    if variant == "A" {
        // Use current multi-strategy approach
        return ab.classifyWithMultiStrategy(ctx, req)
    } else if variant == "B" {
        // Use enhanced approach
        return ab.classifyWithEnhancedStrategy(ctx, req)
    }
    
    // Track results
    ab.trackResult(variant, result)
    return result, nil
}
```

### 6.3 Real-Time Accuracy Monitoring

**File**: `internal/classification/classification_accuracy_monitoring.go` (enhance existing)

**Implementation**:

```go
// CheckAccuracyThreshold - Alert if accuracy drops
func (cam *ClassificationAccuracyMonitoring) CheckAccuracyThreshold(ctx context.Context) {
    accuracy := cam.GetOverallAccuracy()
    
    if accuracy < 0.95 {
        cam.alert("Industry accuracy below 95% threshold", accuracy)
    }
}
```

---

## Phase 7: Testing & Calibration (Week 7)

### 7.1 Unit Tests

**Files to Create/Update**:

- `internal/classification/multi_strategy_classifier_test.go`
- `internal/classification/nlp/entity_recognizer_test.go`
- `internal/classification/nlp/topic_modeler_test.go`
- `internal/classification/repository/supabase_repository_test.go`

**Coverage Target**: >90%

### 7.2 Integration Tests

**File**: `internal/classification/integration_test.go` (update existing)

**Test Scenarios**:

- Full classification pipeline
- ML validation trigger
- Code generation
- Caching behavior
- Performance benchmarks

### 7.3 Accuracy Tests

**File**: `scripts/run_accuracy_tests.sh` (update existing)

**Targets**:

- Industry accuracy: >95%
- Code accuracy: >90%
- Response time: <10s (P99)

### 7.4 Performance Tests

**File**: `scripts/run_performance_tests.sh` (new)

**Targets**:

- P50: <2s
- P95: <5s
- P99: <10s
- Throughput: 1000+ req/s

---

## Implementation Checklist

### Phase 1: Fix Multi-Strategy Classifier

- [ ] Fix keyword strategy (leverage trigram indexes)
- [ ] Fix entity recognition (expand patterns)
- [ ] Fix topic modeling (calibrate TF-IDF)
- [ ] Fix co-occurrence (add relationship analysis)
- [ ] Fix combination logic (simple weighted average)

### Phase 2: Performance Optimizations

- [ ] Implement multi-strategy parallelization
- [ ] Add query batching
- [ ] Enhance caching (predictive, warming)
- [ ] Implement parallel code generation
- [ ] Add priority queue

### Phase 3: ML Enhancement

- [ ] Implement ML trigger logic (confidence >0.8)
- [ ] Add ML validation (not replacement)
- [ ] Implement consensus boosting

### Phase 4: Database Optimization

- [ ] Leverage trigram indexes
- [ ] Leverage full-text search
- [ ] Implement query batching
- [ ] Optimize connection pooling

### Phase 5: Legacy Code Removal

- [ ] Remove MultiMethodClassifier
- [ ] Remove legacy website cache
- [ ] Remove backup files (.bak)
- [ ] Remove unused pattern matching functions
- [ ] Remove unused classification methods
- [ ] Clean up unused imports and types

### Phase 6: Best-in-Class Features

- [ ] Implement continuous learning system
- [ ] Add A/B testing framework
- [ ] Implement real-time accuracy monitoring
- [ ] Add adaptive thresholds

### Phase 7: Testing & Calibration

- [ ] Write unit tests (>90% coverage)
- [ ] Write integration tests
- [ ] Run accuracy tests (target >95%)
- [ ] Run performance tests (target <10s)

---

## Expected Outcomes

### Accuracy Improvements

- **Industry Accuracy**: 0% → 95%+
- **Code Accuracy**: 4.2% → 90%+
- **Overall Accuracy**: 2.52% → 95%+

### Performance Improvements

- **Response Time (P50)**: 7.34s → <2s (73% faster)
- **Response Time (P95)**: 7.34s → <5s (32% faster)
- **Response Time (P99)**: 7.34s → <10s (meets target)
- **Cache Hit Rate**: 0% → 70-80%
- **Database Queries**: Reduced by 80-90% (batching)

### Code Quality Improvements

- **Lines Removed**: ~3000+ (legacy code)
- **Test Coverage**: >90%
- **Code Complexity**: Reduced (simplified logic)

---

## Risk Mitigation

### Backward Compatibility

- Keep API endpoints working during transition
- Maintain existing response formats
- Provide clear migration paths

### Feature Flags

- Use flags to switch between old and new implementations
- Enable gradual rollout
- Allow rollback capabilities

### Monitoring

- Track metrics during transition
- Monitor error rates
- Alert on accuracy drops

---

## Timeline

| Phase | Duration | Deliverable |

|-------|----------|-------------|

| Phase 1: Fix Strategies | 2 weeks | Each strategy >85% accurate |

| Phase 2: Performance | 1 week | <2s response time (P50) |

| Phase 3: ML Enhancement | 1 week | ML validation working |

| Phase 4: Database | 1 week | Optimized queries |

| Phase 5: Legacy Cleanup | 1 week | Legacy code removed |

| Phase 6: Best-in-Class | 1 week | Learning, A/B testing |

| Phase 7: Testing | 1 week | >95% accuracy validated |

| **Total** | **8 weeks** | **Production-ready system** |

---

## Success Criteria

### Must Have

- Industry Accuracy: >95%
- Code Accuracy: >90%
- Response Time: <10s (P99), <5s (P95), <2s (P50)
- ML Trigger: Only if confidence >0.8
- Output Format: Primary industry, MCC, NAICS, SIC, explanation, confidence
- Legacy Code: All removed

### Nice to Have

- Industry Accuracy: >98%
- Code Accuracy: >95%
- Response Time: <5s (P99), <2s (P95), <1s (P50)
- Cache Hit Rate: >80%
- Throughput: 1000+ requests/second